{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/WomenInDataScience-Seattle/FortuneCookie/blob/master/FortuneCookieModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Add the pre-trained embedding layer to our model following this guide: https://keras.io/examples/pretrained_word_embeddings/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "BejHjC3CiFuz",
    "outputId": "b09b27a6-2b3a-40b8-a026-cbbafb1b3750"
   },
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "url='https://raw.githubusercontent.com/WomenInDataScience-Seattle/Machine_Learning_Projects/master/FortuneCookie/training_data/data.csv'\n",
    "s=requests.get(url).text\n",
    "\n",
    "c=pd.read_csv(StringIO(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "16Odw0QilbEq"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "c6AkF2BolVTX",
    "outputId": "1c1c99ea-6fe7-4da2-e0a9-52f4d7cdd1f8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# from tf.keras.models import Sequential  # This does not work!\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, GRU, Embedding, LSTM, Dropout\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.initializers import Constant\n",
    "import keras.utils as ku "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '/home/jovyan/training_data/'\n",
    "GLOVE_DIR = os.path.join(BASE_DIR, '')\n",
    "TEXT_DATA_DIR = os.path.join(BASE_DIR, '20_newsgroup')\n",
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "MAX_NUM_WORDS = 20000\n",
    "EMBEDDING_DIM = 100\n",
    "VALIDATION_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing word vectors.\n",
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "print('Indexing word vectors.')\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt')) as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, 'f', sep=' ')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "Nd0FBWS6JaZ4",
    "outputId": "ec324c26-1467-4fae-dbff-0f821d497c98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting random-word\n",
      "  Using cached https://files.pythonhosted.org/packages/95/0d/c672ff7d6e36f88e60cbdd669f1247041fb7a45f3e2368d314f65b1dd933/Random_Word-1.0.4-py3-none-any.whl\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from random-word) (2.22.0)\n",
      "Collecting nose (from random-word)\n",
      "  Using cached https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->random-word) (1.25.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->random-word) (2019.6.16)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->random-word) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->random-word) (3.0.4)\n",
      "Installing collected packages: nose, random-word\n",
      "Successfully installed nose-1.3.7 random-word-1.0.4\n"
     ]
    }
   ],
   "source": [
    "# random-word used to generate the first word in the sequence\n",
    "!pip install random-word\n",
    "from random_word import RandomWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "13ARdISSlrxx",
    "outputId": "b4f28ce9-9142-4448-9265-a4015364c781"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fortune Cookie Quotes</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Be a generous friend and a fair enemy</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Never quit!</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Old friends, old wines and old gold are best</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>If your desires are not extravagant, they will...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Every Friend Joys in your Success</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Fortune Cookie Quotes Unnamed: 1\n",
       "0              Be a generous friend and a fair enemy        NaN\n",
       "1                                       Never quit!         NaN\n",
       "2      Old friends, old wines and old gold are best         NaN\n",
       "3  If your desires are not extravagant, they will...        NaN\n",
       "4                 Every Friend Joys in your Success         NaN"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dHx91AFinuwd"
   },
   "outputs": [],
   "source": [
    "fortune_data = c['Fortune Cookie Quotes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "dDSs-9YJn6Ev",
    "outputId": "5534015c-dc83-4ec7-d15e-555f0eea0a0b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                Be a generous friend and a fair enemy\n",
       "1                                         Never quit! \n",
       "2        Old friends, old wines and old gold are best \n",
       "3    If your desires are not extravagant, they will...\n",
       "4                   Every Friend Joys in your Success \n",
       "Name: Fortune Cookie Quotes, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fortune_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1BMBwoWyn8nR",
    "outputId": "a03eff9a-7a6b-470b-b784-38b1fd0278ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Never quit! '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fortune_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "n99z-X7eoYFc",
    "outputId": "473b8e6d-8cc6-464c-d215-a291800c7a79"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Let your heart make your decisions - it does not get as confused as your head. '"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fortune_data[36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pBktFaJWocwt"
   },
   "outputs": [],
   "source": [
    "cleaned_df = fortune_data.str.lower()\n",
    "cleaned_df2 = cleaned_df.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_nfUEjbSqyFE"
   },
   "outputs": [],
   "source": [
    "dropped = cleaned_df2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "FFOOUj5vph87",
    "outputId": "65011552-baed-4ef8-9d23-fe0fd3bbdb7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1188    your quick wits will get you out of a tough si...\n",
       "1189                       your reputation is your wealth\n",
       "1190                  your success will astonish everyone\n",
       "1191    your talents will be recognized and suitably r...\n",
       "1192    your work interests can capture the highest st...\n",
       "Name: Fortune Cookie Quotes, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropped.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dn2DmsrorPy6"
   },
   "outputs": [],
   "source": [
    "cleaned_fortunes = dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "zdRKaWLTrswk",
    "outputId": "ba2f1f33-4325-4ab2-fd57-1fc8d5c077d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                be a generous friend and a fair enemy\n",
       "1                                          never quit!\n",
       "2         old friends, old wines and old gold are best\n",
       "3    if your desires are not extravagant, they will...\n",
       "4                    every friend joys in your success\n",
       "Name: Fortune Cookie Quotes, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_fortunes.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "E-ANP8gPrxUg",
    "outputId": "f33d6343-1506-463c-d60c-3281e1cbbcf6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'if your desires are not extravagant, they will be granted'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_fortunes[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "efNR4aIOG5ND",
    "outputId": "55535c91-5113-49b6-a4b6-c47a632fc45c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'be a generous friend and a fair enemy'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_fortunes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1PMN4PXBHw_A"
   },
   "outputs": [],
   "source": [
    "corpus = cleaned_fortunes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "cnCUcwFrHXNA",
    "outputId": "f31829a9-af6a-4ac4-839f-9f4bbc57de4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[10, 6],\n",
       " [10, 6, 345],\n",
       " [10, 6, 345, 128],\n",
       " [10, 6, 345, 128, 8],\n",
       " [10, 6, 345, 128, 8, 6],\n",
       " [10, 6, 345, 128, 8, 6, 598],\n",
       " [10, 6, 345, 128, 8, 6, 598, 289],\n",
       " [23, 961],\n",
       " [109, 85],\n",
       " [109, 85, 109]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "def get_sequence_of_tokens(corpus):\n",
    "    ## tokenization\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    total_words = len(tokenizer.word_index) + 1\n",
    "    \n",
    "    ## convert data to sequence of tokens \n",
    "    input_sequences = []\n",
    "    for line in corpus:\n",
    "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "        for i in range(1, len(token_list)):\n",
    "            n_gram_sequence = token_list[:i+1]\n",
    "            input_sequences.append(n_gram_sequence)\n",
    "    return input_sequences, total_words, tokenizer\n",
    "\n",
    "inp_sequences, total_words, tokenizer1 = get_sequence_of_tokens(corpus)\n",
    "inp_sequences[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching the size of the pre-trained embedding layer to fit our fortune cookie training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer1.word_index\n",
    "# prepare embedding matrix\n",
    "num_words = min(MAX_NUM_WORDS, total_words)\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i >= MAX_NUM_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.49886     0.76602     0.89750999 ... -0.41179001  0.40538999\n",
      "   0.78504002]\n",
      " [-0.038194   -0.24487001  0.72812003 ... -0.1459      0.82779998\n",
      "   0.27061999]\n",
      " ...\n",
      " [-0.46709001 -0.59401     0.29403999 ...  0.042159    0.012113\n",
      "  -0.08221   ]\n",
      " [ 0.38521001  0.099276    0.81708997 ... -0.55181003  0.65854001\n",
      "  -0.43109   ]\n",
      " [ 0.59025002 -0.0016107   0.42640001 ... -0.36791     0.54280001\n",
      "   0.30950999]]\n"
     ]
    }
   ],
   "source": [
    "print(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(num_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            embeddings_initializer=Constant(embedding_matrix),\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D7vaZS3MLG3A"
   },
   "outputs": [],
   "source": [
    "def generate_padded_sequences(input_sequences):\n",
    "    max_sequence_len = max([len(x) for x in input_sequences])\n",
    "    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "    \n",
    "    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "    label = ku.to_categorical(label, num_classes=total_words)\n",
    "    return predictors, label, max_sequence_len\n",
    "\n",
    "predictors, label, max_sequence_len = generate_padded_sequences(inp_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "264b1UmtP1Ac",
    "outputId": "4a00bf1a-a01e-440b-f298-cd0728d5ac1a"
   },
   "outputs": [],
   "source": [
    "predictors[60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "colab_type": "code",
    "id": "0HvQEnQ6QsAk",
    "outputId": "6d10d35b-d792-4eb7-dfc8-a9d902853816"
   },
   "outputs": [],
   "source": [
    "def create_model(max_sequence_len, total_words):\n",
    "    input_len = max_sequence_len - 1\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Add Input Embedding Layer\n",
    "    model.add(Embedding(total_words, 50, input_length=input_len))\n",
    "    \n",
    "    # Add Hidden Layer 1 - LSTM Layer\n",
    "    model.add(GRU(100, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # Add Output Layer\n",
    "    model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model(max_sequence_len, total_words)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "CqC8-uVZRyqn",
    "outputId": "59f4079e-8ac8-47d9-dfa3-1a54d14e982f"
   },
   "outputs": [],
   "source": [
    "model.fit(predictors, label, epochs=100, verbose=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p71b18pXSLvD"
   },
   "outputs": [],
   "source": [
    "# the original generate text function from https://www.kaggle.com/shivamb/beginners-guide-to-text-generation-using-lstms\n",
    "\n",
    "def generate_text(seed_text, next_words, model, max_sequence_len):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        predicted = model.predict_classes(token_list, verbose=0)\n",
    "        \n",
    "        output_word = \"\"\n",
    "        for word,index in tokenizer.word_index.items():\n",
    "            print(predicted)\n",
    "            print(np.sum(predicted))\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \"+output_word\n",
    "    return seed_text.title()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zs0Nb6HWUAN3"
   },
   "outputs": [],
   "source": [
    "# tweaked generate text function that uses np.random.choice to sample of the probaility distribution of the predicted word\n",
    "\n",
    "def generate_text_prob(seed_text, next_words, model, max_sequence_len):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        predicted = model.predict_proba(token_list, verbose=0)\n",
    "        random = np.random.choice(predicted.shape[1],1, p=predicted[0])\n",
    "        \n",
    "        output_word = \"\"\n",
    "        for word,index in tokenizer.word_index.items():\n",
    "            if index == random:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \"+output_word\n",
    "    return seed_text.title()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "gLfVx6bjmEj8",
    "outputId": "48edb44a-62f6-4e28-c484-cbb89e3499a7"
   },
   "outputs": [],
   "source": [
    "token_list = tokenizer.texts_to_sequences('you')[0]\n",
    "token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "predicted = model.predict_proba(token_list, verbose=0)\n",
    "random = np.random.choice(predicted.shape[1],1, p=predicted[0])\n",
    "\n",
    "print(random)\n",
    "predicted[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AjT8Zl4EXjiv",
    "outputId": "c1673a98-b49b-4bf9-e223-f3d8733c3c97"
   },
   "outputs": [],
   "source": [
    "r = RandomWords()\n",
    "random_word = 'Dreams'\n",
    "text = generate_text_prob(random_word, 7, model, max_sequence_len)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uy2Vr0-er6IV"
   },
   "source": [
    "What we did today: \n",
    "- we changed to gru \n",
    "- we increased the word embedding length\n",
    "- we increased the dropout\n",
    "- we changed the activation from tanh to relu\n",
    "- we randomly sampled our probaility distribution of word predictions\n",
    "\n",
    "Next time:\n",
    "- Use a pre-trained word embedding applied to our corpus\n",
    "- get more data\n",
    "- try training\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "FortuneCookieModel.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
