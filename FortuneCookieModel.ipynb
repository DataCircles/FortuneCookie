{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/WomenInDataScience-Seattle/FortuneCookie/blob/master/FortuneCookieModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "BejHjC3CiFuz",
    "outputId": "b09b27a6-2b3a-40b8-a026-cbbafb1b3750"
   },
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "url='https://raw.githubusercontent.com/WomenInDataScience-Seattle/Machine_Learning_Projects/master/FortuneCookie/training_data/data.csv'\n",
    "s=requests.get(url).text\n",
    "\n",
    "c=pd.read_csv(StringIO(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "16Odw0QilbEq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "c6AkF2BolVTX",
    "outputId": "1c1c99ea-6fe7-4da2-e0a9-52f4d7cdd1f8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# from tf.keras.models import Sequential  # This does not work!\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, GRU, Embedding, LSTM, Dropout\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "import keras.utils as ku "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "Nd0FBWS6JaZ4",
    "outputId": "ec324c26-1467-4fae-dbff-0f821d497c98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting random-word\n",
      "  Using cached https://files.pythonhosted.org/packages/95/0d/c672ff7d6e36f88e60cbdd669f1247041fb7a45f3e2368d314f65b1dd933/Random_Word-1.0.4-py3-none-any.whl\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from random-word) (2.22.0)\n",
      "Collecting nose (from random-word)\n",
      "  Using cached https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->random-word) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->random-word) (2019.6.16)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->random-word) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->random-word) (1.25.3)\n",
      "Installing collected packages: nose, random-word\n",
      "Successfully installed nose-1.3.7 random-word-1.0.4\n"
     ]
    }
   ],
   "source": [
    "# random-word used to generate the first word in the sequence\n",
    "!pip install random-word\n",
    "from random_word import RandomWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "13ARdISSlrxx",
    "outputId": "b4f28ce9-9142-4448-9265-a4015364c781"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fortune Cookie Quotes</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Be a generous friend and a fair enemy</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Never quit!</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Old friends, old wines and old gold are best</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>If your desires are not extravagant, they will...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Every Friend Joys in your Success</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Fortune Cookie Quotes Unnamed: 1\n",
       "0              Be a generous friend and a fair enemy        NaN\n",
       "1                                       Never quit!         NaN\n",
       "2      Old friends, old wines and old gold are best         NaN\n",
       "3  If your desires are not extravagant, they will...        NaN\n",
       "4                 Every Friend Joys in your Success         NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dHx91AFinuwd"
   },
   "outputs": [],
   "source": [
    "fortune_data = c['Fortune Cookie Quotes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "dDSs-9YJn6Ev",
    "outputId": "5534015c-dc83-4ec7-d15e-555f0eea0a0b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                Be a generous friend and a fair enemy\n",
       "1                                         Never quit! \n",
       "2        Old friends, old wines and old gold are best \n",
       "3    If your desires are not extravagant, they will...\n",
       "4                   Every Friend Joys in your Success \n",
       "Name: Fortune Cookie Quotes, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fortune_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1BMBwoWyn8nR",
    "outputId": "a03eff9a-7a6b-470b-b784-38b1fd0278ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Never quit! '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fortune_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "n99z-X7eoYFc",
    "outputId": "473b8e6d-8cc6-464c-d215-a291800c7a79"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Let your heart make your decisions - it does not get as confused as your head. '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fortune_data[36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pBktFaJWocwt"
   },
   "outputs": [],
   "source": [
    "cleaned_df = fortune_data.str.lower()\n",
    "cleaned_df2 = cleaned_df.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_nfUEjbSqyFE"
   },
   "outputs": [],
   "source": [
    "dropped = cleaned_df2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "FFOOUj5vph87",
    "outputId": "65011552-baed-4ef8-9d23-fe0fd3bbdb7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1188    your quick wits will get you out of a tough si...\n",
       "1189                       your reputation is your wealth\n",
       "1190                  your success will astonish everyone\n",
       "1191    your talents will be recognized and suitably r...\n",
       "1192    your work interests can capture the highest st...\n",
       "Name: Fortune Cookie Quotes, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropped.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dn2DmsrorPy6"
   },
   "outputs": [],
   "source": [
    "cleaned_fortunes = dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "zdRKaWLTrswk",
    "outputId": "ba2f1f33-4325-4ab2-fd57-1fc8d5c077d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                be a generous friend and a fair enemy\n",
       "1                                          never quit!\n",
       "2         old friends, old wines and old gold are best\n",
       "3    if your desires are not extravagant, they will...\n",
       "4                    every friend joys in your success\n",
       "Name: Fortune Cookie Quotes, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_fortunes.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "E-ANP8gPrxUg",
    "outputId": "f33d6343-1506-463c-d60c-3281e1cbbcf6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'if your desires are not extravagant, they will be granted'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_fortunes[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "efNR4aIOG5ND",
    "outputId": "55535c91-5113-49b6-a4b6-c47a632fc45c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'be a generous friend and a fair enemy'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_fortunes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1PMN4PXBHw_A"
   },
   "outputs": [],
   "source": [
    "corpus = cleaned_fortunes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "cnCUcwFrHXNA",
    "outputId": "f31829a9-af6a-4ac4-839f-9f4bbc57de4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[10, 6],\n",
       " [10, 6, 345],\n",
       " [10, 6, 345, 128],\n",
       " [10, 6, 345, 128, 8],\n",
       " [10, 6, 345, 128, 8, 6],\n",
       " [10, 6, 345, 128, 8, 6, 598],\n",
       " [10, 6, 345, 128, 8, 6, 598, 289],\n",
       " [23, 961],\n",
       " [109, 85],\n",
       " [109, 85, 109]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "def get_sequence_of_tokens(corpus):\n",
    "    ## tokenization\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    total_words = len(tokenizer.word_index) + 1\n",
    "    \n",
    "    ## convert data to sequence of tokens \n",
    "    input_sequences = []\n",
    "    for line in corpus:\n",
    "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "        for i in range(1, len(token_list)):\n",
    "            n_gram_sequence = token_list[:i+1]\n",
    "            input_sequences.append(n_gram_sequence)\n",
    "    return input_sequences, total_words\n",
    "\n",
    "inp_sequences, total_words = get_sequence_of_tokens(corpus)\n",
    "inp_sequences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D7vaZS3MLG3A"
   },
   "outputs": [],
   "source": [
    "def generate_padded_sequences(input_sequences):\n",
    "    max_sequence_len = max([len(x) for x in input_sequences])\n",
    "    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "    \n",
    "    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "    label = ku.to_categorical(label, num_classes=total_words)\n",
    "    return predictors, label, max_sequence_len\n",
    "\n",
    "predictors, label, max_sequence_len = generate_padded_sequences(inp_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "264b1UmtP1Ac",
    "outputId": "4a00bf1a-a01e-440b-f298-cd0728d5ac1a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  60, 963, 221,\n",
       "         8,  33], dtype=int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors[60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "colab_type": "code",
    "id": "0HvQEnQ6QsAk",
    "outputId": "6d10d35b-d792-4eb7-dfc8-a9d902853816"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 41, 50)            104350    \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 100)               45300     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2087)              210787    \n",
      "=================================================================\n",
      "Total params: 360,437\n",
      "Trainable params: 360,437\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model(max_sequence_len, total_words):\n",
    "    input_len = max_sequence_len - 1\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Add Input Embedding Layer\n",
    "    model.add(Embedding(total_words, 50, input_length=input_len))\n",
    "    \n",
    "    # Add Hidden Layer 1 - LSTM Layer\n",
    "    model.add(GRU(100, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # Add Output Layer\n",
    "    model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model(max_sequence_len, total_words)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "CqC8-uVZRyqn",
    "outputId": "59f4079e-8ac8-47d9-dfa3-1a54d14e982f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd5485d9e10>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(predictors, label, epochs=1, verbose=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p71b18pXSLvD"
   },
   "outputs": [],
   "source": [
    "# the original generate text function from https://www.kaggle.com/shivamb/beginners-guide-to-text-generation-using-lstms\n",
    "\n",
    "def generate_text(seed_text, next_words, model, max_sequence_len):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        predicted = model.predict_classes(token_list, verbose=0)\n",
    "        \n",
    "        output_word = \"\"\n",
    "        for word,index in tokenizer.word_index.items():\n",
    "            print(predicted)\n",
    "            print(np.sum(predicted))\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \"+output_word\n",
    "    return seed_text.title()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zs0Nb6HWUAN3"
   },
   "outputs": [],
   "source": [
    "# tweaked generate text function that uses np.random.choice to sample of the probaility distribution of the predicted word\n",
    "\n",
    "def generate_text_prob(seed_text, next_words, model, max_sequence_len):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        predicted = model.predict_proba(token_list, verbose=0)\n",
    "        random = np.random.choice(predicted.shape[1],1, p=predicted[0])\n",
    "        \n",
    "        output_word = \"\"\n",
    "        for word,index in  x :\n",
    "            if index == random:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \"+output_word\n",
    "    return seed_text.title()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "gLfVx6bjmEj8",
    "outputId": "48edb44a-62f6-4e28-c484-cbb89e3499a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2087,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_list = tokenizer.texts_to_sequences('you')[0]\n",
    "token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "predicted = model.predict_proba(token_list, verbose=0)\n",
    "random = np.random.choice(predicted.shape[1],1, p=predicted[0])\n",
    "\n",
    "print(random)\n",
    "predicted[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AjT8Zl4EXjiv",
    "outputId": "c1673a98-b49b-4bf9-e223-f3d8733c3c97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dreams Fear Grief Notice Proven Wonâ€™T Just You\n"
     ]
    }
   ],
   "source": [
    "r = RandomWords()\n",
    "random_word = 'Dreams'\n",
    "text = generate_text_prob(random_word, 7, model, max_sequence_len)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "340"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_word = randint(0, 2087)\n",
    "random_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequences_to_texts_generator() missing 1 required positional argument: 'sequences'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-f5a8de714a5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequences_to_texts_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: sequences_to_texts_generator() missing 1 required positional argument: 'sequences'"
     ]
    }
   ],
   "source": [
    "Tokenizer.sequences_to_texts_generator([1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Tokenizer' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-7b0684d5e520>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtoken_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m340\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtoken_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Tokenizer' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "token_list = tokenizer[340]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-56-6397aa8bcad5>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-56-6397aa8bcad5>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    tokenizer.index_word.[340]\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "tokenizer.index_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uy2Vr0-er6IV"
   },
   "source": [
    "What we did today: \n",
    "- we changed to gru \n",
    "- we increased the word embedding length\n",
    "- we increased the dropout\n",
    "- we changed the activation from tanh to relu\n",
    "- we randomly sampled our probaility distribution of word predictions\n",
    "\n",
    "Next time:\n",
    "- Use a pre-trained word embedding applied to our corpus\n",
    "- get more data\n",
    "- try training\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "FortuneCookieModel.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
